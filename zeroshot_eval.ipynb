{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"babylm_evaluate\"\n",
    "models_dir = [d for d in os.listdir(eval_path) if os.path.isdir(os.path.join(eval_path, d))]\n",
    "col_names = os.listdir(eval_path+\"/\"+models_dir[0]+\"/zeroshot\")\n",
    "\n",
    "json_path_template = eval_path+\"/{}/zeroshot/{}/eval_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for model in models_dir:\n",
    "    results = {}\n",
    "    for col in col_names:\n",
    "        json_path = json_path_template.format(model, col)\n",
    "        val = json.load(open(json_path))['eval_accuracy']\n",
    "        results[col] = val\n",
    "    data[model] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi_licensing</th>\n",
       "      <th>determiner_noun_agreement</th>\n",
       "      <th>control_raising</th>\n",
       "      <th>quantifiers</th>\n",
       "      <th>island_effects</th>\n",
       "      <th>irregular_forms</th>\n",
       "      <th>binding</th>\n",
       "      <th>argument_structure</th>\n",
       "      <th>subject_verb_agreement</th>\n",
       "      <th>anaphor_agreement</th>\n",
       "      <th>ellipsis</th>\n",
       "      <th>filler_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-instruction</th>\n",
       "      <td>0.776799</td>\n",
       "      <td>0.958764</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763009</td>\n",
       "      <td>0.739910</td>\n",
       "      <td>0.960305</td>\n",
       "      <td>0.776046</td>\n",
       "      <td>0.809287</td>\n",
       "      <td>0.885998</td>\n",
       "      <td>0.995399</td>\n",
       "      <td>0.821016</td>\n",
       "      <td>0.770619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-babylm-instruction</th>\n",
       "      <td>0.768600</td>\n",
       "      <td>0.946964</td>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.712777</td>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.743247</td>\n",
       "      <td>0.786009</td>\n",
       "      <td>0.882204</td>\n",
       "      <td>0.986196</td>\n",
       "      <td>0.803695</td>\n",
       "      <td>0.732182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2</th>\n",
       "      <td>0.765563</td>\n",
       "      <td>0.959162</td>\n",
       "      <td>0.800044</td>\n",
       "      <td>0.719217</td>\n",
       "      <td>0.783259</td>\n",
       "      <td>0.957761</td>\n",
       "      <td>0.789403</td>\n",
       "      <td>0.839961</td>\n",
       "      <td>0.880578</td>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.851039</td>\n",
       "      <td>0.809679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-babylm</th>\n",
       "      <td>0.804889</td>\n",
       "      <td>0.939804</td>\n",
       "      <td>0.771984</td>\n",
       "      <td>0.797012</td>\n",
       "      <td>0.719731</td>\n",
       "      <td>0.958779</td>\n",
       "      <td>0.768626</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.874435</td>\n",
       "      <td>0.991309</td>\n",
       "      <td>0.838915</td>\n",
       "      <td>0.750856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-medium-babylm-instruction</th>\n",
       "      <td>0.829942</td>\n",
       "      <td>0.957438</td>\n",
       "      <td>0.821697</td>\n",
       "      <td>0.857548</td>\n",
       "      <td>0.700673</td>\n",
       "      <td>0.952672</td>\n",
       "      <td>0.783467</td>\n",
       "      <td>0.807590</td>\n",
       "      <td>0.856007</td>\n",
       "      <td>0.994888</td>\n",
       "      <td>0.842379</td>\n",
       "      <td>0.725646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-medium-instruction</th>\n",
       "      <td>0.798968</td>\n",
       "      <td>0.961018</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.797785</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>0.939440</td>\n",
       "      <td>0.776640</td>\n",
       "      <td>0.795951</td>\n",
       "      <td>0.881120</td>\n",
       "      <td>0.995399</td>\n",
       "      <td>0.823903</td>\n",
       "      <td>0.753657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-medium</th>\n",
       "      <td>0.773003</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.827221</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.803812</td>\n",
       "      <td>0.947583</td>\n",
       "      <td>0.778124</td>\n",
       "      <td>0.834020</td>\n",
       "      <td>0.882204</td>\n",
       "      <td>0.995910</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.814970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_results_gpt2-medium-babylm</th>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.960488</td>\n",
       "      <td>0.822802</td>\n",
       "      <td>0.909067</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.961323</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.875700</td>\n",
       "      <td>0.996421</td>\n",
       "      <td>0.885104</td>\n",
       "      <td>0.751945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             npi_licensing  \\\n",
       "eval_results_gpt2-instruction                     0.776799   \n",
       "eval_results_gpt2-babylm-instruction              0.768600   \n",
       "eval_results_gpt2                                 0.765563   \n",
       "eval_results_gpt2-babylm                          0.804889   \n",
       "eval_results_gpt2-medium-babylm-instruction       0.829942   \n",
       "eval_results_gpt2-medium-instruction              0.798968   \n",
       "eval_results_gpt2-medium                          0.773003   \n",
       "eval_results_gpt2-medium-babylm                   0.837534   \n",
       "\n",
       "                                             determiner_noun_agreement  \\\n",
       "eval_results_gpt2-instruction                                 0.958764   \n",
       "eval_results_gpt2-babylm-instruction                          0.946964   \n",
       "eval_results_gpt2                                             0.959162   \n",
       "eval_results_gpt2-babylm                                      0.939804   \n",
       "eval_results_gpt2-medium-babylm-instruction                   0.957438   \n",
       "eval_results_gpt2-medium-instruction                          0.961018   \n",
       "eval_results_gpt2-medium                                      0.966057   \n",
       "eval_results_gpt2-medium-babylm                               0.960488   \n",
       "\n",
       "                                             control_raising  quantifiers  \\\n",
       "eval_results_gpt2-instruction                       0.790323     0.763009   \n",
       "eval_results_gpt2-babylm-instruction                0.765135     0.712777   \n",
       "eval_results_gpt2                                   0.800044     0.719217   \n",
       "eval_results_gpt2-babylm                            0.771984     0.797012   \n",
       "eval_results_gpt2-medium-babylm-instruction         0.821697     0.857548   \n",
       "eval_results_gpt2-medium-instruction                0.807556     0.797785   \n",
       "eval_results_gpt2-medium                            0.827221     0.730036   \n",
       "eval_results_gpt2-medium-babylm                     0.822802     0.909067   \n",
       "\n",
       "                                             island_effects  irregular_forms  \\\n",
       "eval_results_gpt2-instruction                      0.739910         0.960305   \n",
       "eval_results_gpt2-babylm-instruction               0.680120         0.961832   \n",
       "eval_results_gpt2                                  0.783259         0.957761   \n",
       "eval_results_gpt2-babylm                           0.719731         0.958779   \n",
       "eval_results_gpt2-medium-babylm-instruction        0.700673         0.952672   \n",
       "eval_results_gpt2-medium-instruction               0.735800         0.939440   \n",
       "eval_results_gpt2-medium                           0.803812         0.947583   \n",
       "eval_results_gpt2-medium-babylm                    0.753363         0.961323   \n",
       "\n",
       "                                              binding  argument_structure  \\\n",
       "eval_results_gpt2-instruction                0.776046            0.809287   \n",
       "eval_results_gpt2-babylm-instruction         0.743247            0.786009   \n",
       "eval_results_gpt2                            0.789403            0.839961   \n",
       "eval_results_gpt2-babylm                     0.768626            0.806256   \n",
       "eval_results_gpt2-medium-babylm-instruction  0.783467            0.807590   \n",
       "eval_results_gpt2-medium-instruction         0.776640            0.795951   \n",
       "eval_results_gpt2-medium                     0.778124            0.834020   \n",
       "eval_results_gpt2-medium-babylm              0.770703            0.810863   \n",
       "\n",
       "                                             subject_verb_agreement  \\\n",
       "eval_results_gpt2-instruction                              0.885998   \n",
       "eval_results_gpt2-babylm-instruction                       0.882204   \n",
       "eval_results_gpt2                                          0.880578   \n",
       "eval_results_gpt2-babylm                                   0.874435   \n",
       "eval_results_gpt2-medium-babylm-instruction                0.856007   \n",
       "eval_results_gpt2-medium-instruction                       0.881120   \n",
       "eval_results_gpt2-medium                                   0.882204   \n",
       "eval_results_gpt2-medium-babylm                            0.875700   \n",
       "\n",
       "                                             anaphor_agreement  ellipsis  \\\n",
       "eval_results_gpt2-instruction                         0.995399  0.821016   \n",
       "eval_results_gpt2-babylm-instruction                  0.986196  0.803695   \n",
       "eval_results_gpt2                                     0.996933  0.851039   \n",
       "eval_results_gpt2-babylm                              0.991309  0.838915   \n",
       "eval_results_gpt2-medium-babylm-instruction           0.994888  0.842379   \n",
       "eval_results_gpt2-medium-instruction                  0.995399  0.823903   \n",
       "eval_results_gpt2-medium                              0.995910  0.867206   \n",
       "eval_results_gpt2-medium-babylm                       0.996421  0.885104   \n",
       "\n",
       "                                             filler_gap  \n",
       "eval_results_gpt2-instruction                  0.770619  \n",
       "eval_results_gpt2-babylm-instruction           0.732182  \n",
       "eval_results_gpt2                              0.809679  \n",
       "eval_results_gpt2-babylm                       0.750856  \n",
       "eval_results_gpt2-medium-babylm-instruction    0.725646  \n",
       "eval_results_gpt2-medium-instruction           0.753657  \n",
       "eval_results_gpt2-medium                       0.814970  \n",
       "eval_results_gpt2-medium-babylm                0.751945  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
